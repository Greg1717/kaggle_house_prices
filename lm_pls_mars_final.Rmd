---
title: "Caret Pre-Processing"
author: "Gergely Horvath"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: inline
---

Goal

It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. 


Metric

Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted_pls value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)

# Load Libraries
```{r}
library(earth)
library(shiny)
library(miniUI)
library(ggplot2)
library(data.table)
library(caret)
library(doParallel)
library(outliers)
library(pls)
library(broom)
library(scales)
```

# Set Up Shiny Gadget
```{r}
ggbrush <- function(data, xvar, yvar) {

  ui <- miniPage(
    gadgetTitleBar("Drag to select points"),
    miniContentPanel(
      # The brush="brush" argument means we can listen for
      # brush events on the plot using input$brush.
      plotOutput("plot", height = "100%", brush = "brush")
    )
  )

  server <- function(input, output, session) {

    # Render the plot
    output$plot <- renderPlot({
      # Plot the data with x/y vars indicated by the caller.
      ggplot(data, aes_string(xvar, yvar)) + geom_point()
    })

    # Handle the Done button being pressed.
    observeEvent(input$done, {
      # Return the brushed points. See ?shiny::brushedPoints.
      stopApp(brushedPoints(data, input$brush))
    })
  }

  runGadget(ui, server)
}
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)
```


# Import Data

```{r}
data_descr <- read.csv(file = "data/data_description.txt")
sample_submission <- read.csv(file = "data/sample_submission.csv")
ds_test <- read.csv(file = "data/test.csv")
ds_test <- as.data.table(ds_test)
ds_test$SalePrice <- NA
ds_test$status <- "test"
ds_train <- read.csv(file = "data/train.csv")
ds_train <- as.data.table(ds_train)
ds_train$status <- "train"

ds_all <- rbind(ds_train, ds_test)

remove(ds_train)
remove(ds_test)
```

## Clean Up NAs in order to get rid of incomplete cases

```{r}
ds_all[!complete.cases(ds_all)]
ds_all[, table(Fence, useNA = "always")]
ds_all[is.na(Fence), Fence := "no_info"]
ds_all[, table(Alley, useNA = "always")]
ds_all[is.na(Alley), Alley := "no_info"]

ds_all[, table(FireplaceQu, useNA = "always")]
ds_all[is.na(FireplaceQu), FireplaceQu := "no_info"]
ds_all[, table(LotFrontage, useNA = "always")]
ds_all[is.na(LotFrontage), LotFrontage := 0]
ds_all[, table(GarageType, useNA = "always")]
ds_all[is.na(GarageType), GarageType := "na"]
ds_all[, table(GarageFinish, useNA = "always")]
ds_all[is.na(GarageFinish), GarageFinish := "na"]
ds_all[, table(BsmtQual, useNA = "always")]
ds_all[is.na(BsmtQual), BsmtQual := "na"]
ds_all[is.na(BsmtExposure), BsmtExposure := "na"]
ds_all[is.na(BsmtFinSF1), BsmtFinSF1 := 0]
ds_all[is.na(BsmtFinSF2), BsmtFinSF2 := 0]
ds_all[is.na(BsmtFinType1), BsmtFinType1 := "na"]
ds_all[is.na(BsmtFinType2), BsmtFinType2 := "na"]
ds_all[is.na(BsmtFullBath), BsmtFullBath := 0]
ds_all[is.na(BsmtHalfBath), BsmtHalfBath := 0]
ds_all[is.na(BsmtUnfSF), BsmtUnfSF := 0]

ds_all[is.na(KitchenQual), KitchenQual := "na"]
ds_all[is.na(BsmtCond), BsmtCond := "na"]
ds_all[is.na(MasVnrType), MasVnrType := "na"]
ds_all[is.na(MasVnrArea), MasVnrArea := 0]
ds_all[is.na(MSZoning), MSZoning := "na"]

ds_all[is.na(GarageArea), GarageArea := 0]
ds_all[is.na(GarageQual), GarageQual := "na"]
ds_all[is.na(GarageCond), GarageCond := "na"]

ds_all[, table(GarageYrBlt, useNA = "always")]
ds_all[is.na(GarageYrBlt), GarageYrBlt := 0]
ds_all[, table(Electrical, useNA = "always")]
ds_all[is.na(Electrical), Electrical := "none"]
ds_all[!complete.cases(ds_all)]
```



## Rich Neighborhood Category

Both the median and mean Saleprices agree on 3 neighborhoods with substantially higher saleprices. The separation of the 3 relatively poor neighborhoods is less clear, but at least both graphs agree on the same 3 poor neighborhoods. Since I do not want to 'overbin', I am only creating categories for those 'extremes'.

```{r}
ds_all$NeighRich[ds_all$Neighborhood %in% c('StoneBr', 'NridgHt', 'NoRidge')] <- 3
ds_all$NeighRich[!ds_all$Neighborhood %in% c('MeadowV', 'IDOTRR', 'BrDale', 'StoneBr', 'NridgHt', 'NoRidge')] <- 2
ds_all$NeighRich[ds_all$Neighborhood %in% c('MeadowV', 'IDOTRR', 'BrDale')] <- 1

table(ds_all$NeighRich)
```


# Clean Up Training Data


## Remove Predictors with too many NAs
```{r id}
trn <- copy(ds_all[status == "train"])
# determine which variables should be kept, nr. of NAs low
var_na <- trn[, colMeans(is.na(trn)) < .95]

# show variables which will be removed
trn[, -..var_na]

# remove NA vars
trn <- trn[, ..var_na]
remove(var_na)
trn
```




## Remove Near-Zero-Variance Predictors

Near-Zero-Variance that will be removed from dataset:
```{r}
near_zero_vars <- nearZeroVar(trn,freqCut = 95/5)
trn[, ..near_zero_vars]
```

```{r}
trn <- trn[, -c(..near_zero_vars)]
remove(near_zero_vars)
head(trn)
```



## Reduce Collinearity

Correlation matrix:
```{r}
trn[!complete.cases(trn)]

# get numeric columns
charidx <- unname(sapply(trn, function(x) is.numeric(x)))
dt_nr <- trn[, ..charidx]

# exclude SalePrice as we only want to analyze the correlation of predictors
dt_nr <- dt_nr[, -c("SalePrice")]

# also exclude TotRmsAbvGrd as it correlates strongly with variable GrLivArea, which we want to keep
dt_nr <- dt_nr[, -c("TotRmsAbvGrd")]
remove(charidx)

correlations <- cor(dt_nr, use = "complete.obs")

corrplot::corrplot(correlations, order = "hclust",tl.cex = 0.5)
```

Identify high correlation variables:
```{r}
highCorr <- findCorrelation(correlations, cutoff = 0.75, names = T)
head(trn[, ..highCorr])
```

Relevance of OverallQual, with which other varibles does it correlate?
```{r}
trn[, table(OverallQual)]
sort(correlations[,"OverallQual"],decreasing = T)
```


Remove high correlation variables:

```{r}
trn <- trn[, -(..highCorr)]
remove(highCorr)
remove(correlations)
# remove(dt_nr)
trn
```

## Linear Dependencies
```{r}
combo_info <- findLinearCombos(dt_nr[, -c("GarageYrBlt")])
remove(dt_nr)
combo_info
remove(combo_info)
```


## Remove Individual Lines
```{r}
# remove these positions as prediction works terribly bad, there is something very unusual
trn <- trn[!Id %in% c("524","1299")]
# trn <- trn[!Id %in% c("524", "692", "1183", "1299")]
```


## Exclude Less Relevant Features (based on linear regression analysis)

```{r}
names_to_keep <- names(trn)[!names(trn) %in% c("SaleType", "TotRmsAbvGrd", "CentralAirY", "MoSold", "YrSold", "GarageFinish")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("Exterior")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("Electrical")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("ExterCond")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("HeatingQC")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("Fence")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("GarageType")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("LotShape")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("Paved")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("RoofStyle")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("^Foundation")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("YearRemodAdd")]
trn <- trn[, ..names_to_keep]
names_to_keep <- names(trn)[!names(trn) %like% c("FireplaceQu")]
trn <- trn[, ..names_to_keep]
```



## Create Linear Model to Assess Importance of Variables

```{r}
# prepare training scheme
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

# train the model
model_lm <- train(SalePrice ~ ., 
               data = trn, 
               method = "lm", 
               preProcess = "scale", 
               trControl = control)
remove(control)
summary(model_lm)
```



### LM Coef Analysis (readable)

Which are the most relevant variables to determine the sales price?
First of all create a linear model and check results in summary().

```{r}
an_model_lm <- lm(formula = SalePrice ~ ., 
                  data = trn)
summary(an_model_lm)

coefs <- tidy(an_model_lm)
remove(an_model_lm)
coefs <- coefs[order(coefs$p.value),]
coefs$p.value <- with(coefs, 
                      ifelse(abs(p.value) > .1, paste0(formatC(p.value, format = "e", digits = 2),""),
                             ifelse(abs(p.value) > .05, paste0(formatC(p.value, format = "e", digits = 2),"."),
                                    ifelse(abs(p.value) > .01, paste0(formatC(p.value, format = "e", digits = 2),"*"),
                                           ifelse(abs(p.value) > .001, paste0(formatC(p.value, format = "e", digits = 2),"**"),
                                           paste0(formatC(p.value, format = "e", digits = 2),"***"))))))
coefs <- as.data.table(coefs)
coefs
```

Review less relevant coefficients/variables:
```{r}
tail(coefs[!is.na(estimate) & 
             !term %like% "^Neighborhood" & 
             !term %like% "^SaleCondition"][order(term)], 55)
coefs[term %like% "GarageFinish"]
remove(coefs)
```

## Rank Features By Importance

```{r}

# estimate variable importance
importance <- varImp(model_lm, scale = FALSE)
remove(model_lm)
# summarize importance
print(importance)
# plot importance
plot(importance, cex.axis = 0.1)

# TODO research how to reduce font size on variable importance

dt_imp <- as.data.table(importance$importance, keep.rownames = T)
remove(importance)
head(dt_imp)
```

```{r}

dt_imp[Overall > 2][order(Overall, decreasing = T)]
```

```{r}
dt_imp[Overall < 1][order(Overall, decreasing = T)]
remove(dt_imp)
```


## Neighbourhood

### Binning Neighborhood

```{r}
nb1 <-
  ggplot(trn[!is.na(trn$SalePrice), ], aes(
    x = reorder(Neighborhood, SalePrice, FUN = median),
    y = SalePrice
  )) +
  geom_bar(stat = 'summary',
           fun.y = "median",
           fill = 'blue') + labs(x = 'Neighborhood', y = 'Median SalePrice') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous(breaks = seq(0, 800000, by = 50000), labels = comma) +
  geom_label(stat = "count",
             aes(label = ..count.., y = ..count..),
             size = 3) +
  geom_hline(yintercept = 163000,
             linetype = "dashed",
             color = "red") #dashed line is median SalePrice


nb2 <-
  ggplot(trn[!is.na(trn$SalePrice), ], aes(x = reorder(Neighborhood, SalePrice, FUN =
                                                         mean), y = SalePrice)) +
  geom_bar(stat = 'summary',
           fun.y = "mean",
           fill = 'blue') + labs(x = 'Neighborhood', y = "Mean SalePrice") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous(breaks = seq(0, 800000, by = 50000), labels = comma) +
  geom_label(stat = "count",
             aes(label = ..count.., y = ..count..),
             size = 3) +
  geom_hline(yintercept = 163000,
             linetype = "dashed",
             color = "red") #dashed line is median SalePrice

gridExtra::grid.arrange(nb1, nb2)
remove(nb1)
remove(nb2)
```


# Dummy Variables

```{r}
ds_train_dummies <- predict(dummyVars(" ~ .", data = trn), newdata = trn)

ds_train_dummies <- as.data.frame(ds_train_dummies)

# remove dummy because it does not exist in the test set
ds_train_dummies$HouseStyle2.5Fin <- NULL
ds_train_dummies$GarageQualEx <- NULL
ds_train_dummies$Id <- NULL
ds_train_dummies
```



# TRAIN MODELS

## PLS

### Train Model PLS

```{r}
# introduce a quadratic element of OverallQual as the price of high quality houses is being underestimated strongly by the prediction
# trn$OverallQual2 <- trn$OverallQual^2
# trn[, OverallQual := NULL]

model_pls <-
  plsr(
    formula = SalePrice ~ . + poly(NeighRich, 2),
    # data = trn,
    data = ds_train_dummies,
    scale = T,
    center = T,
    validation = "CV",
    ncomp = 14
  )

summary(model_pls)
```


RMSE is 24,679 (see line 'CV')
Variance explained by model (see line 'X'): 33.57%?



### Plot Model PLS

```{r}
plot(model_pls)
```


### Validation Plot

```{r}
validationplot(model_pls)
```

MSEP plot:
```{r}
validationplot(model_pls, val.type="MSEP")
```


R2 plot:
```{r}
validationplot(model_pls, val.type="R2")
```


### Prediction & ggbrush() of Training Set

```{r}
pred_train_pls <- predict(model_pls, ds_train_dummies, ncomp = 14)
# shiny
# ggbrush(ds_train_dummies, "SalePrice", "pred_train_pls")
```


### Plot Observed vs Prediction

```{r}
plot(x = ds_train_dummies$SalePrice, y = pred_train_pls)
abline(0,1)
```


### Plot Prediction vs Residuals

```{r}
plot(x = model_pls$fitted.values, y = model_pls$residuals)
```


### RMSE

```{r}
rmse_pls <- round(sqrt(mean((pred_train_pls - trn$SalePrice)^2)), 0)
rmse_pls
```


### Prediction Test Set

Convert test data to dummies:

```{r}
ds_test <- ds_all[status == "test", -c("SalePrice")]
vars <- names(ds_test) %in% names(trn)
ds_test <- ds_test[, ..vars]
ds_test[!complete.cases(ds_test)]
remove(vars)
ds_test_dummies <- predict(dummyVars(" ~ .", data = ds_test), newdata = ds_test)
ds_test_dummies <- as.data.frame(ds_test_dummies)
ds_test_dummies
```


Predict:

```{r}
pred_test_pls <- predict(model_pls, ds_test_dummies, ncomp = 14)
head(pred_test_pls)
```


## MARS

```{r}
#count unique values for each variable
sapply(lapply(trn, unique), length)
```

### Train Model MARS (earth)
```{r}
ds_train_dummies <- as.data.table(ds_train_dummies)
str(ds_train_dummies)
model_mars_earth <- earth(ds_train_dummies[, -c("SalePrice")], ds_train_dummies$SalePrice)
# predict train
pred_train_mars_earth <- predict(model_mars_earth, ds_train_dummies[, -c("SalePrice")])
pred_train_mars_earth <- as.vector(pred_train_mars_earth)
model_mars_earth
```

### Summary MARS (earth)
```{r}
summary(model_mars_earth)
```

### Plot MARS (earth)
```{r}
plot(model_mars_earth)
```

### Plot Observed vs Prediction MARS (earth)
```{r}
?base::plot
plot(x = I(ds_train_dummies$SalePrice), y = ds_train_dummies$predicted_mars)
abline(0,1)
```


### Plot Prediction vs Residuals

```{r}
plot(x = model_mars_earth$fitted.values, y = model_mars_earth$residuals)
```


### RMSE

```{r}
rmse_mars_earth <- round(sqrt(mean((pred_train_mars_earth - ds_train_dummies$SalePrice)^2)), 0)
rmse_mars_earth
```

### Predict test set
```{r}
pred_test_mars_earth <- predict(model_mars_earth, ds_test_dummies)
pred_test_mars_earth <- as.vector(pred_test_mars_earth)
```



## MARS - CARET

### Train Model

```{r}
indx <- createFolds(ds_train_dummies$SalePrice, returnTrain = TRUE)
ctrl <- trainControl(method = "cv", index = indx)
model_mars_caret <-
  train(
    x = ds_train_dummies[, -c("SalePrice")],
    y = ds_train_dummies$SalePrice,
    method = "earth",
    preProcess = c("BoxCox", "center", "scale"),
    # tuneGrid = expand.grid(degree = 1, nprune = 2:38),
    trControl = ctrl
  )

pred_train_mars_caret <- as.vector(predict(model_mars_caret, ds_train_dummies[, -c("SalePrice", "predicted_pls")]))

model_mars_caret
```

```{r}
summary(model_mars_caret)
```

```{r}
plot(model_mars_caret)
```

### Plot Observed vs Prediction
```{r}
plot(x = ds_train_dummies$SalePrice, y = pred_train_mars_caret)
abline(0,1)
```


### Plot Prediction vs Residuals

```{r}
plot(
  x = pred_train_mars_caret,
  y = (
    pred_train_mars_caret - ds_train_dummies$SalePrice
  )
)
```


### RMSE

```{r}
rmse_mars_caret <- round(sqrt(mean((pred_train_mars_caret - ds_train_dummies$SalePrice)^2)), 0)
rmse_mars_caret
```

### Predict test set
```{r}
pred_test_mars_caret <- predict(model_mars_caret, ds_test_dummies)
pred_test_mars_caret <- as.vector(pred_test_mars_caret)
```


```{r}
marsImp <- varImp(model_mars_caret)
plot(marsImp)
```


## SVM - CARET
```{r}
model_svm_caret <- caret::train(
        SalePrice ~ .,
        data = ds_train_dummies,
        preProcess = c("BoxCox", "center", "scale"),
        method = "svmRadial"
)
model_svm_caret$results
rmse_svm <- min(model_svm_caret$results$RMSE)
```


## RF - CARET

```{r}
# check CPU in terminal: sysctl -a | grep machdep.cpu
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

model_rf_caret <- caret::train(
        SalePrice ~ .,
        data = ds_train_dummies,
        preProcess = c("BoxCox", "center", "scale"),
        method = "rf"
)

stopCluster(cl)
remove(cl)

model_rf_caret$results
rmse_rf <- min(model_rf_caret$results$RMSE)
```


# Submission

```{r}
submission <- data.frame(Id = ds_test$Id,  SalePrice = pred_test_mars_caret)
submission

write.table(
        submission,
        file = "submission.csv",
        row.names = F,
        sep = ",",
        quote = FALSE
)
```


