---
title: "Caret Pre-Processing"
author: "Gergely Horvath"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Goal

It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. 

## Metric

Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted_pls value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)

# Settings 
```{r}
plot_tf <- FALSE
run_SAFS <- FALSE
```

# Load Libraries
```{r}
library(earth)
library(shiny)
library(miniUI)
library(ggplot2)
library(data.table)
library(caret)
library(doParallel)
library(outliers)
library(pls)
library(broom)
library(scales)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)
```

# Import Data
Load data and rbind test set and training set.
```{r}
data_descr <- read.csv(file = "data/data_description.txt")
sample_submission <- read.csv(file = "data/sample_submission.csv")
ds_test <- read.csv(file = "data/test.csv")
ds_test <- as.data.table(ds_test)
ds_test$SalePrice <- NA
ds_test$status <- "test"
ds_train <- read.csv(file = "data/train.csv")
ds_train <- as.data.table(ds_train)
ds_train$status <- "train"
ds_all <- rbind(ds_train, ds_test)

ds_all[, table(MSZoning)]
ds_all[MSZoning == "C (all)", MSZoning := "all"]

remove(ds_train)
remove(ds_test)
str(ds_all)
```

## Convert All Character Vectors to Factors
```{r}
# char_cols <- sapply(ds_all, is.character)
# lapply(ds_all[, ..char_cols], unique)
# sapply(lapply(ds_all[, ..char_cols], unique), length)
# 
# # ds_all[, (char_cols) := lapply(.SD, factor()),
# #        .SDcols = char_cols]
# 
# # Convert all character columns to factors
# ds_all <- as.data.frame(ds_all)
# ds_all[char_cols] <- lapply(ds_all[char_cols], factor)
# str(ds_all)
```

# Preprocess
## Remove Predictors with too many NAs
The following variables will be removed from both training and test sets:
```{r show NA vars to be removed}
# determine which variables should be kept, i.e. number of NAs low
var_na <- ds_all[, colMeans(is.na(ds_all)) < .98]
ds_all[, -..var_na]
```

```{r remove NA vars}
ds_all <- ds_all[, ..var_na]
remove(var_na)
head(ds_all)
```

## Normalization
```{r}
# preprocess and define subsets
normalization <- preProcess(ds_all[, -c("Id", "SalePrice", "status")])
norm <- predict(normalization, ds_all[, -c("Id", "SalePrice", "status")])
remove(normalization)
norm$status <- ds_all$status
norm$Id <- ds_all$Id
head(norm)
```

## Convert NAs in order to get rid of incomplete cases
```{r}
# tidyverse method using across() =============================================
# library(purrr)
# library(dplyr)
# library(tidyr)
# ds_all %>% 
#   mutate(
#     across(where(is.numeric), ~replace_na(.x, 0))
#   ) %>%
#   as.data.table()

# data.table with keep ========================================================
# does almost the same, but returns only is.numeric columns
# as.data.table(lapply(keep(ds_all, is.numeric), function(x) replace(x, is.na(x), 0)))

# data.table with Filter and lapply ===========================================
# replace NA with zero in numeric columns
numeric_names <- names(Filter(function(x) is.numeric(x), norm))
norm[, (numeric_names) := lapply(.SD, function(x) replace(x, is.na(x), 0)),
       .SDcols = numeric_names]
remove(numeric_names)
# replace NA with 'na' in character columns
character_names <- names(Filter(function(x) is.character(x), norm))
norm[, (character_names) := lapply(.SD, function(x) replace(x, is.na(x), "na")),
       .SDcols = character_names]
remove(character_names)
tail(norm)
head(norm)
```

## Create Dummy Variables
```{r}
# trn <- ds_all[status == "train", -"status"]
#count unique values for each variable; there should be no variables with only 1 value because it would cause an error in the next step (and also it wouldn't make sense to have such a variable)
# sapply(lapply(trn, unique), length)

# =============================================================================
# _____DEV______ ==============================================================
# update this chung, first dummification, then search for correlated variables, so that all variables are included in the search for correlated VARs.
# =============================================================================
  
# dummification
dummification_transf <- dummyVars(" ~ .", data = norm[, -c("status", "Id")])
dt <- predict(dummification_transf, newdata = norm)
remove(dummification_transf)
remove(norm)
dt <- as.data.table(dt)
str(dt, list.len = ncol(dt))
dt$status <- ds_all$status
dt$Id <- ds_all$Id
head(dt)
```

## Remove Near-Zero-Variance Predictors
Following variables have near-zero variance:
```{r print near zero variance predictors}
near_zero_vars <- nearZeroVar(dt[status == "train", -c("status")],freqCut = 99/1)
dt[status == "train", ..near_zero_vars]
```

Dataset after removal of near-zero-variance variables
```{r remove near zero variance predictors}
dt <- dt[, -c(..near_zero_vars)]
remove(near_zero_vars)
head(dt)
```

## Reduce Collinearity

Correlation matrix:
```{r}

idx <- unname(sapply(dt[status == "train", -c("status", "Id")], function(x) is.numeric(x)))
dt_nr <- dt[status == "train", ..idx]
remove(idx)
# check for incomplete cases; there should be none as we have replaced NAs
dt_nr[!complete.cases(dt_nr)]
correlations <- cor(dt_nr, use = "everything")
if ("plot_tf" == TRUE) {
  corrplot::corrplot(correlations, order = "hclust", tl.cex = 0.5)
}
```

Identify high correlation variables:
```{r}
highCorr <- findCorrelation(correlations, cutoff = 0.75, names = T)
head(dt_nr[, ..highCorr])
```

Remove high correlation variables and plot again:
```{r}
correlations <- cor(dt_nr[, -..highCorr], use = "everything")
remove(dt_nr)
if ("plot_tf" == TRUE) {
  corrplot::corrplot(correlations, order = "hclust", tl.cex = 0.8)
}
```


Just an example on sorting correlations
Relevance of OverallQual, with which other varibles does it correlate?
```{r}
sort(correlations[,"OverallQual"],decreasing = T)
```


Remove high correlation variables from training and test sets:
```{r}
dt <- dt[, -(..highCorr)]
remove(highCorr)
remove(correlations)
head(dt)
```

## Linear Dependencies
```{r}
str(dt, list.len = ncol(dt))
combo_info <- findLinearCombos(dt[, -c("status", "Id")])
combo_info$linearCombos
vars_remove <- combo_info$remove
# to be removed:
dt[, ..vars_remove]
dt <- dt[, -..vars_remove]
remove(vars_remove)
remove(combo_info)
str(dt, list.len = ncol(dt))
dt[1]
```

```{r}
predictors <- dt[status == "train", -c("status", "Id")]
outcome <- ds_all[status == "train"]$SalePrice
```

# Feature Selection
```{r}
# subsets <- c(1:10, 15, 30, 50)
# set.seed(10)
# ctrl <- rfeControl(functions = lmFuncs,
#                    method = "repeatedcv",
#                    repeats = 5,
#                    verbose = TRUE)
# 
# y <- ds_all[status == "train"]$SalePrice
# x <- dt[status == "train", -c("status", "Id")]
# x <- as.data.frame(x)
# names(x) <- gsub(pattern = "\\.", replacement = "_", x = names(x))
# names(x)
# # contrasts can be applied only to factors with 2 or more levels
# lmProfile <- rfe(x, 
#                  y,
#                  sizes = subsets,
#                  rfeControl = ctrl)
# 
# lmProfile
```

## Simulated annealing feature selection
```{r}
if (run_SAFS == TRUE) {
  ctrl <- safsControl(functions = caretSA)
  safs_obj <- safs(
    predictors,
    outcome,
    iters = 100,
    safsControl = ctrl,
    method = "lm"
  )
  remove(ctrl)
  safs_obj
  safs_vars <- safs_obj$optVariables
}
```

```{r}
if (run_SAFS == TRUE) {
  plot(obj) + theme_bw()
}
```

```{r}
names(getModelInfo())
```


# Train Models
## LM
```{r}
# TODO Apply stratified random sampling!
ctrl <- trainControl(method = "cv", 
                     number = 10) 

lmFit1 <- train(x = predictors, 
                y = outcome,
                method = "lm", 
                trControl = ctrl)
rmse_lm <- lmFit1$results$RMSE
rsquared_lm <- lmFit1$results$Rsquared
```

```{r}
if (run_SAFS == TRUE) {
  ctrl <- trainControl(method = "cv",
                       number = 10)
  lmFit1_safs <- train(
    x = predictors[, ..safs_vars],
    y = outcome,
    method = "lm",
    trControl = ctrl
  )
  rmse_lm_safs <- lmFit1_safs$results$RMSE
  rsquared_lm_safs <- lmFit1_safs$results$Rsquared
}
```

## MARS
```{r}
indx <- createFolds(outcome, returnTrain = TRUE)
ctrl <- trainControl(method = "cv", index = indx)
model_mars_caret <-
  train(
    x = predictors,
    y = outcome,
    method = "earth",
    trControl = ctrl
  )
remove(indx)
remove(ctrl)
rmse_mars <- min(model_mars_caret$results$RMSE)
rsquared_mars <- max(model_mars_caret$results$Rsquared)
varImp(model_mars_caret)
```

## RF
```{r}
model_rf <-
  train(
    x = predictors,
    y = outcome,
    method = "rf"
  )
rmse_rf <- min(model_rf$results$RMSE)
rsquared_rf <- max(model_rf$results$Rsquared)
varImp(model_rf)
```

## PLS
```{r}
model_pls <-
  train(
    x = predictors,
    y = outcome,
    method = "pls"
  )
model_pls
rmse_pls <- min(model_pls$results$RMSE)
rsquared_pls <- max(model_pls$results$Rsquared)
varImp(model_pls)
```

```{r}
if (run_SAFS == TRUE) {
  model_pls_safs <-
    train(x = predictors[, ..safs_vars],
          y = outcome,
          method = "pls")
  model_pls_safs
  rmse_pls_safs <- min(model_pls_safs$results$RMSE)
  rsquared_pls_safs <- max(model_pls_safs$results$Rsquared)
}
```

MARS and RF provide the best results.
MARS and RF also have the benefit that they conduct intrinsic feature selection!
Feature selection with SAFS did not show any benefit in this case; at this moment I do not see how it can be useful. It seems much more efficient to get the list of most relevant predictors from varImp() of the RF and MARS models.

# varImp() MARS and RF
```{r}
var_imp_mars <- varImp(model_mars_caret)$importance
var_imp_mars$feature <- rownames(var_imp_mars)
var_imp_mars <- as.data.table(var_imp_mars)
var_imp_mars

var_imp_rf <- varImp(model_rf)$importance
var_imp_rf$feature <- rownames(var_imp_rf)
var_imp_rf <- as.data.table(var_imp_rf)
var_imp_rf <- var_imp_rf[order(Overall, decreasing = TRUE)]
var_imp_rf[Overall > 1]
var_imp_rf[Overall > 1 & feature %in% var_imp_mars$feature]

```

# Current Issues


## NAs:
When I remove NAs, i.e. replace them by 'na' or by zero, do I have to perform this for both the test set and training set?
- tree-based techniques can specifically account for missing data.


### Solution

- tree-based techniques can specifically account for missing data.
- correlations cannot be calculated on NA lines, but with zeros it can!
- removal is needed on both, it makes sense to replace NA numerics with zero in this current dataset. 


## Dummy variables: 

- shall I create it in one step for both training and test set? 
- are dummy variables required for all ML models, or just some of them?

Caret package assumes that all values are numeric, i.e. dummification is required for all models!


